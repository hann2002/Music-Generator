{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece]\n",
    "!apt install git-lfs\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "context_length = 256\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"local_wrapped_tokenizer\")\n",
    "\n",
    "# process data (check length、output wrong data、label content to input_ids)\n",
    "def tokenize(element):\n",
    "    removed_elements_counter = 0\n",
    "    outputs = tokenizer(\n",
    "        element[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "        else:\n",
    "            removed_elements_counter += 1\n",
    "    print(f\"Removed chunks with size less than context_size: {removed_elements_counter}\")\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "# process data\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize, batched=True, remove_columns=raw_datasets[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model config\n",
    "from transformers import TFGPT2LMHeadModel, AutoConfig\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "# build model\n",
    "model = TFGPT2LMHeadModel(config)\n",
    "model(model.dummy_inputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data_collator (tensorflow)\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False, return_tensors=\"tf\")\n",
    "\n",
    "# tensorflow dataset\n",
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=8\n",
    ")\n",
    "tf_eval_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model param.\n",
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "num_epochs = 10\n",
    "num_train_steps = len(tf_train_dataset) * num_epochs\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=5e-5,\n",
    "    num_warmup_steps=1_000,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function (generate 3 midi files per epoch)\n",
    "from transformers import pipeline\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "!pip install note_seq\n",
    "import note_seq\n",
    "\n",
    "BPM_1_SECOND = 60\n",
    "\n",
    "# Variables to change based on the time signature\n",
    "numerator = \"\"\n",
    "denominator = \"\"\n",
    "\n",
    "def token_sequence_to_note_sequence(token_sequence, \n",
    "                                    use_program=True, \n",
    "                                    use_drums=True, \n",
    "                                    instrument_mapper=None, \n",
    "                                    only_piano=False):\n",
    "\n",
    "    if isinstance(token_sequence, str):\n",
    "        token_sequence = token_sequence.split()\n",
    "\n",
    "    note_sequence = empty_note_sequence()\n",
    "\n",
    "    # Render all notes.\n",
    "    current_program = 1\n",
    "    current_is_drum = False\n",
    "    current_instrument = 0\n",
    "    track_count = 0\n",
    "    for token_index, token in enumerate(token_sequence):\n",
    "\n",
    "        if token == \"PIECE_START\":\n",
    "            pass\n",
    "        elif token == \"PIECE_END\":\n",
    "            print(\"The end.\")\n",
    "            break\n",
    "        elif token.startswith(\"TIME_SIGNATURE=\"):\n",
    "            time_signature_str = token.split(\"=\")[-1]\n",
    "            numerator = int(time_signature_str.split(\"_\")[0])\n",
    "            denominator = int(time_signature_str.split(\"_\")[-1])\n",
    "            time_signature = note_sequence.time_signatures.add()\n",
    "            time_signature.numerator = numerator\n",
    "            time_signature.denominator = denominator\n",
    "        elif token.startswith(\"BPM=\"):\n",
    "            bpm_str = token.split(\"=\")[-1]\n",
    "            bpm = int(bpm_str)\n",
    "            note_sequence.tempos[0].qpm = bpm\n",
    "            pulse_duration, bar_duration = duration_in_sec(\n",
    "                bpm, numerator, denominator\n",
    "            )\n",
    "        elif token == \"TRACK_START\":\n",
    "            current_bar_index = 0\n",
    "            track_count += 1\n",
    "            pass\n",
    "        elif token == \"TRACK_END\":\n",
    "            pass\n",
    "        elif token == \"KEYS_START\":\n",
    "            pass\n",
    "        elif token == \"KEYS_END\":\n",
    "            pass\n",
    "        elif token.startswith(\"KEY=\"):\n",
    "            pass\n",
    "        elif token.startswith(\"INST\"):\n",
    "            instrument = token.split(\"=\")[-1]\n",
    "            if instrument != \"DRUMS\" and use_program:\n",
    "                if instrument_mapper is not None:\n",
    "                    if instrument in instrument_mapper:\n",
    "                        instrument = instrument_mapper[instrument]\n",
    "                current_program = int(instrument)\n",
    "                current_instrument = track_count\n",
    "                current_is_drum = False\n",
    "            if instrument == \"DRUMS\" and use_drums:\n",
    "                current_instrument = 0\n",
    "                current_program = 0\n",
    "                current_is_drum = True\n",
    "        elif token == \"BAR_START\":\n",
    "            current_time = (current_bar_index * bar_duration)\n",
    "            current_notes = {}\n",
    "        elif token == \"BAR_END\":\n",
    "            current_bar_index += 1\n",
    "            pass\n",
    "        elif token.startswith(\"NOTE_ON\"):\n",
    "            pitch = int(token.split(\"=\")[-1])\n",
    "            note = note_sequence.notes.add()\n",
    "            note.start_time = current_time\n",
    "            note.end_time = current_time + denominator * pulse_duration\n",
    "            note.pitch = pitch\n",
    "            note.instrument = current_instrument\n",
    "            note.program = current_program\n",
    "            note.velocity = 80\n",
    "            note.is_drum = current_is_drum\n",
    "            current_notes[pitch] = note\n",
    "        elif token.startswith(\"NOTE_OFF\"):\n",
    "            pitch = int(token.split(\"=\")[-1])\n",
    "            if pitch in current_notes:\n",
    "                note = current_notes[pitch]\n",
    "                note.end_time = current_time\n",
    "        elif token.startswith(\"TIME_DELTA\"):\n",
    "            delta = float(token.split(\"=\")[-1]) * (0.25) * pulse_duration\n",
    "            current_time += delta\n",
    "        elif token.startswith(\"DENSITY=\"):\n",
    "            pass\n",
    "        elif token == \"[PAD]\":\n",
    "            pass\n",
    "        else:\n",
    "            #print(f\"Ignored token {token}.\")\n",
    "            pass\n",
    "\n",
    "    # Make the instruments right.\n",
    "    instruments_drums = []\n",
    "    for note in note_sequence.notes:\n",
    "        pair = [note.program, note.is_drum]\n",
    "        if pair not in instruments_drums:\n",
    "            instruments_drums += [pair]\n",
    "        note.instrument = instruments_drums.index(pair)\n",
    "\n",
    "    if only_piano:\n",
    "        for note in note_sequence.notes:\n",
    "            if not note.is_drum:\n",
    "                note.instrument = 0\n",
    "                note.program = 0\n",
    "\n",
    "    return note_sequence\n",
    "\n",
    "def duration_in_sec(bpm, numerator, denominator):\n",
    "    pulse_duration = BPM_1_SECOND / bpm\n",
    "    number_of_quarters_per_bar = (4 / denominator) * numerator\n",
    "    bar_duration = pulse_duration * number_of_quarters_per_bar\n",
    "    return pulse_duration, bar_duration\n",
    "\n",
    "def empty_note_sequence(qpm=120, total_time=0.0):\n",
    "    note_sequence = note_seq.protobuf.music_pb2.NoteSequence()\n",
    "    note_sequence.tempos.add().qpm = qpm\n",
    "    #note_sequence.ticks_per_quarter = note_seq.constants.STANDARD_PPQ\n",
    "    note_sequence.total_time = total_time\n",
    "    return note_sequence\n",
    "\n",
    "class GenerateAndSaveCallback(Callback):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.generation_seed = \"PIECE_START TIME_SIGNATURE=4_4 BPM=120 TRACK_START INST=0 DENSITY=2 BAR_START NOTE_ON=43\"\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pipe = pipeline(\n",
    "            \"text-generation\", model=self.model, tokenizer=self.tokenizer, device=0\n",
    "        )\n",
    "        for i in range(3):\n",
    "            generated_text = pipe(self.generation_seed, max_length=500)[0][\"generated_text\"]\n",
    "            note_sequence = token_sequence_to_note_sequence(generated_text)\n",
    "            midi_filename = f\"epoch_{epoch}_{i}.mid\"\n",
    "            note_seq.note_sequence_to_midi_file(note_sequence, midi_filename)\n",
    "            print(f\"Generated MIDI for epoch {epoch} saved as {midi_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint (gen midi)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "generate_and_save_callback = GenerateAndSaveCallback(model, tokenizer)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=\"check/check_{epoch}\",\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_loss\", \n",
    "    save_best_only=False,\n",
    "    mode=\"min\", \n",
    "    save_freq=\"epoch\",\n",
    ")\n",
    "\n",
    "# train + save loss history\n",
    "history = model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=[checkpoint_callback, generate_and_save_callback],\n",
    ")\n",
    "\n",
    "# save Tokenizer\n",
    "tokenizer.save_pretrained(\"save_tokenizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get loss history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "# plot loss\n",
    "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# save pic\n",
    "plt.savefig('loss_plot.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
